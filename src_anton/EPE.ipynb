{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np # numpy library\n",
    "import scipy . linalg as lng # linear algebra from scipy library\n",
    "from scipy . spatial import distance # load distance function\n",
    "from sklearn import preprocessing as preproc # load preprocessing function\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV       \n",
    "from sklearn.datasets import make_regression        \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (80, 116)\n",
      "X_test:  (20, 116)\n",
      "y_train:  (80,)\n",
      "y_test:  (20,)\n",
      "X_new:  (1000, 116)\n",
      "n_train:  80\n",
      "n_test:  20\n",
      "p:  116\n",
      "Number of missing values in X_train:  0\n",
      "Number of missing values in X_test:  0\n",
      "Number of missing values in y_train:  0\n",
      "Number of missing values in y_test:  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading the data into numpy arrays\n",
    "X_train = np.loadtxt('../data/case1Data_Xtrain.csv', delimiter=',')\n",
    "X_test = np.loadtxt('../data/case1Data_Xtest.csv', delimiter=',')\n",
    "y_train = np.loadtxt('../data/case1Data_ytrain.csv', delimiter=',')\n",
    "y_test = np.loadtxt('../data/case1Data_ytest.csv', delimiter=',')\n",
    "X_new = np.loadtxt('../data/case1Data_Xnew_wrangled.csv', delimiter=',')\n",
    "\n",
    "# Printing the shape of the data\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)\n",
    "print(\"X_new: \", X_new.shape)\n",
    "\n",
    "# Size of the training and test data\n",
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "p = X_train.shape[1]\n",
    "\n",
    "# Printing the size of the training and test data\n",
    "print(\"n_train: \", n_train) # number of training samples\n",
    "print(\"n_test: \", n_test) # number of test samples\n",
    "print(\"p: \", p) # number of features/variables/columns/parameters\n",
    "\n",
    "# Checking for missing values in the wrangled data\n",
    "missing_values_X_train = np.isnan(X_train)\n",
    "print(\"Number of missing values in X_train: \", np.sum(missing_values_X_train))\n",
    "missing_values_X_test = np.isnan(X_test)\n",
    "print(\"Number of missing values in X_test: \", np.sum(missing_values_X_test))\n",
    "missing_values_y_train = np.isnan(y_train)\n",
    "print(\"Number of missing values in y_train: \", np.sum(missing_values_y_train))\n",
    "missing_values_y_test = np.isnan(y_test)\n",
    "print(\"Number of missing values in y_test: \", np.sum(missing_values_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have the following:\n",
    "# X_train, y_train (training data with 100 observations)\n",
    "# X_new (new dataset with 1000 observations and no y values)\n",
    "\n",
    "# Step 1: Train the model on the initial 100 observations\n",
    "model = ElasticNetCV(cv=10)  # ElasticNetCV with 10-fold cross-validation\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 2: Predict on the new dataset (1000 observations)\n",
    "y_pred_new = model.predict(X_new)  # Predictions for the new dataset\n",
    "\n",
    "# Now, we'll calculate the EPE using the following components:\n",
    "\n",
    "# Step 3: Estimate the Bias using cross-validation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "cv_predictions = cross_val_predict(model, X_train, y_train, cv=10)\n",
    "bias = np.mean(cv_predictions) - np.mean(y_train)  # Bias is the difference between predicted and true mean\n",
    "bias_squared = bias ** 2\n",
    "\n",
    "# Step 4: Estimate the Variance using bootstrap resampling\n",
    "n_iterations = 100  # Number of bootstrap iterations\n",
    "predictions = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Resample data (bootstrap)\n",
    "    X_resample, y_resample = resample(X_train, y_train, n_samples=len(X_train), random_state=42)\n",
    "    \n",
    "    # Train model on resampled data and predict on X_new\n",
    "    model.fit(X_resample, y_resample)\n",
    "    predictions.append(model.predict(X_new))  # Collect predictions for X_new\n",
    "\n",
    "# Calculate variance of predictions\n",
    "variance = np.var(predictions, axis=0).mean()\n",
    "\n",
    "# Step 5: Estimate the Irreducible Error (σ²ₑ)\n",
    "# This can be approximated as the variance in y_train\n",
    "irreducible_error = np.var(y_train)\n",
    "\n",
    "# Step 6: Calculate the Total EPE\n",
    "EPE = irreducible_error + bias_squared + variance\n",
    "\n",
    "# Print the result\n",
    "print(f\"Total EPE for the new dataset = {EPE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(69.54715769233908)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(EPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.11916449907914212\n",
      "Optimal l1_ratio: 0.5\n",
      "Test set R^2 score: 0.7441530121544222\n",
      "RMSE: 40.86024028863906\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the best alpha and l1_ratio found                \n",
    "print(\"Optimal alpha:\", model.alpha_)                    \n",
    "print(\"Optimal l1_ratio:\", model.l1_ratio_)              \n",
    "# Evaluate the model on the test set                     \n",
    "print(\"Test set R^2 score:\", model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "#predict the target values\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculates RMSE \n",
    "rmse = np.sqrt(np.mean((y_test - y_pred)**2))\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
