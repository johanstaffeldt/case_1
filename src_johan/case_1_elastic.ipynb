{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1 - Elastic-Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Importing Libraries**\n",
    "\n",
    "2. **Loading Data**\n",
    "\n",
    "3. **Elastic Net Regression**\n",
    "- Elastic Net Regression because we have many variables that we do not know. Elastic Net combines the strengths of Lasso regression (L1) and Ridge regression. Lasso regression can shrink parameters to 0 which is useful for large dataset where some parameters might be useless. Ridge regression tends to perform better when parameters are not useless. Therefore, elastic net is useful in this case as we do not know our parameters.\n",
    "- Find optimal model parameters, lamdba_1 and lambda_2 by using 5-fold cross validation.\n",
    "- Get root mean squared error (RMSE) by applying the model with the optimal model parameters on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set() # Set searborn as default\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Set seed for reproducibility\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data into numpy arrays\n",
    "X_train = np.loadtxt('../data/case1Data_Xtrain.csv', delimiter=',')\n",
    "X_test = np.loadtxt('../data/case1Data_Xtest.csv', delimiter=',')\n",
    "y_train = np.loadtxt('../data/case1Data_ytrain.csv', delimiter=',')\n",
    "y_test = np.loadtxt('../data/case1Data_ytest.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be similar to the summary in case_1_data_wrangling.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (80, 116)\n",
      "X_test:  (20, 116)\n",
      "y_train:  (80,)\n",
      "y_test:  (20,)\n",
      "n_train:  80\n",
      "n_test:  20\n",
      "p:  116\n",
      "Number of missing values in X_train:  0\n",
      "Number of missing values in X_test:  0\n",
      "Number of missing values in y_train:  0\n",
      "Number of missing values in y_test:  0\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of the data\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)\n",
    "\n",
    "# Size of the training and test data\n",
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "p = X_train.shape[1]\n",
    "\n",
    "# Printing the size of the training and test data\n",
    "print(\"n_train: \", n_train) # number of training samples\n",
    "print(\"n_test: \", n_test) # number of test samples\n",
    "print(\"p: \", p) # number of features/variables/columns/parameters\n",
    "\n",
    "# Checking for missing values in the wrangled data\n",
    "missing_values_X_train = np.isnan(X_train)\n",
    "print(\"Number of missing values in X_train: \", np.sum(missing_values_X_train))\n",
    "missing_values_X_test = np.isnan(X_test)\n",
    "print(\"Number of missing values in X_test: \", np.sum(missing_values_X_test))\n",
    "missing_values_y_train = np.isnan(y_train)\n",
    "print(\"Number of missing values in y_train: \", np.sum(missing_values_y_train))\n",
    "missing_values_y_test = np.isnan(y_test)\n",
    "print(\"Number of missing values in y_test: \", np.sum(missing_values_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Elastic Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.016681005372000592\n",
      "\n",
      "For l1_ratio = 0 the penalty is an L2 penalty. For l1_ratio = 1 it is an L1 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2.\n",
      "Optimal l1_ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Setting a range of alphas to test\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "\n",
    "# Setting a range of l1_ratios\n",
    "l1_ratios = np.logspace(-10, 0, 100)\n",
    "\n",
    "with warnings.catch_warnings(): # done to disable all the convergence warnings from elastic net\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    # Fitting the Elastic Net model on the training data\n",
    "    model = ElasticNetCV(cv=3, l1_ratio = l1_ratios, alphas=alphas, fit_intercept=False).fit(X_train, y_train)\n",
    "\n",
    "# Printing the optimal alpha\n",
    "print(f'Optimal alpha: {model.alpha_}\\n')\n",
    "print('For l1_ratio = 0 the penalty is an L2 penalty. For l1_ratio = 1 it is an L1 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2.')\n",
    "print(f'Optimal l1_ratio: {model.l1_ratio_}')\n",
    "\n",
    "# Plotting the cross-validated mean squared error of the Elastic Net Fit\n",
    "#plt.close('all')\n",
    "#plt.figure()\n",
    "#plt.semilogx(model.alphas_, model.mse_path_.mean(axis=-1), 'k', label='Average across folds', linewidth=2)\n",
    "#plt.xlabel(r'$\\alpha$ (Regularization strength)')\n",
    "#plt.ylabel('Mean squared error')\n",
    "#plt.title(f'Cross-validated MSE of Elastic Net Fit (Optimal alpha = {model.alpha_:.3f})')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root MSE from OLS with elastic net regression and cross validation to find optimal lambda and model parameters:\n",
      "RMSE: 0.39768204205170693\n"
     ]
    }
   ],
   "source": [
    "# Using the optimal lambda from the ElasticNetCV model to predict the target values on the test data\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "# Calculating the RMSE of the ElasticNetCV model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_hat))\n",
    "\n",
    "# Printing the RMSE\n",
    "print('Root MSE from OLS with elastic net regression and cross validation to find optimal lambda and model parameters:')\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Predicting $\\hat{y}$ in the new data set (case1Data_Xnew.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Loading case1Data_Xnew_wrangled.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_new:  (1000, 116)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data into numpy arrays\n",
    "X_new = np.loadtxt('../data/case1Data_Xnew_wrangled.csv', delimiter=',')\n",
    "print(\"X_new: \", X_new.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Predicting and saving predictions in a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Predicting y_hat for the data in case1Data_Xnew.csv\n",
    "y_hat_new = model.predict(X_new)\n",
    "\n",
    "# Printing the shape of the new data\n",
    "print(y_hat_new.shape)\n",
    "\n",
    "# Saving the predictions to a csv file\n",
    "np.savetxt('../results/sample_predictions_s183220_s225001.csv', y_hat_new, delimiter='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Calculating the expected prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the expected prediction error for the new data in case1Data_Xnew.csv with no true y-values\n",
    "# The expected prediction error is the sum of the squared bias and the variance of the model\n",
    "# The bias is the difference between the expected value of the predictions and the true value\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
